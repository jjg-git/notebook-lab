{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORBb9gFlKsVdbfHMdn/1fL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjg-git/notebook-lab/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QCcEmYwfGR_",
        "outputId": "0e104e63-bb7f-4a13-f233-860eafd8e48c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/4TH-SEM/2ND-TERM/STINTSY-S14/STINTSY-Group-2-Project/dataset-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ti5B9-5iIyW",
        "outputId": "27860bb6-065a-46f2-c30c-58e83850cfe3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'fies_2012_v1_metadata(dictionary).xlsx'   FIES_PUF_2012_Vol.1.vol1_ref\n",
            "'FIES PUF 2012 Vol.1.CSV'\t\t   PHL-PSA-FIES-2012-V1-PUF.zip\n",
            " FIES_PUF_2012_Vol.1.dcf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('drive/MyDrive/4TH-SEM/2ND-TERM/STINTSY-S14/STINTSY-Group-2-Project/dataset-1/FIES PUF 2012 Vol.1.CSV')\n",
        "\n",
        "print(df.to_string())"
      ],
      "metadata": {
        "id": "gkhd2nAEhUOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1. Introduction to the problem/task and dataset\n",
        "Each group should select one real-world dataset from the list of datasets provided for the\n",
        "project. Each dataset is accompanied with a description file, which also contains detailed\n",
        "description of each feature.\n",
        "\n",
        "The target task (i.e., classification or regression) should be properly stated as well."
      ],
      "metadata": {
        "id": "PT1dJDogNvfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2. Description of the dataset\n",
        "\n",
        "In this section of the notebook, you must fulfill the following:\n",
        "* State a brief description of the dataset.\n",
        "* Provide a description of the collection process executed to build the dataset. Discuss the\n",
        "implications of the data collection method on the generated conclusions and insights.\n",
        "* Note that you may need to look at relevant sources related to the dataset to acquire necessary information for this part of the project.\n",
        "* Describe the structure of the dataset file.\n",
        "\n",
        "  * What does each row and column represent?\n",
        "  * How many instances are there in the dataset?\n",
        "  * How many features are there in the dataset?\n",
        "  * If the dataset is composed of different files that you will combine in the succeeding\n",
        "steps, describe the structure and the contents of each file.\n",
        "\n",
        "* Discuss the features in each dataset file. What does each feature represent? All features,\n",
        "even those which are not used for the study, should be described to the reader. The\n",
        "purpose of each feature in the dataset should be clear to the reader of the notebook\n",
        "without having to go through an external link."
      ],
      "metadata": {
        "id": "Nalp9T1ON1cZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3. List of requirements\n",
        "\n",
        "List all the Python libraries and modules that you used."
      ],
      "metadata": {
        "id": "GAgNKHgUORVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4. Data preprocessing and cleaning\n",
        "Perform necessary steps before using the data. In this section of the notebook, please take note\n",
        "of the following:\n",
        "\n",
        "* If needed, perform preprocessing techniques to transform the data to the appropriate\n",
        "representation. This may include binning, log transformations, conversion to one-hot\n",
        "encoding, normalization, standardization, interpolation, truncation, and feature\n",
        "engineering, among others. There should be a correct and proper justification for the use\n",
        "of each preprocessing technique used in the project.\n",
        "* Make sure that the data is clean, especially features that are used in the project. This\n",
        "may include checking for misrepresentations, checking the data type, dealing with\n",
        "missing data, dealing with duplicate data, and dealing with outliers, among others. There\n",
        "should be a correct and proper justification for the application (or non-application) of each data cleaning method used in the project. Clean only the variables utilized in the\n",
        "study.\n"
      ],
      "metadata": {
        "id": "7xX-RkxtOdOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5. Exploratory data analysis\n",
        "Perform exploratory data analysis comprehensively to gain a good understanding of your dataset.\n",
        "In this section of the notebook, you must present relevant numerical summaries and\n",
        "visualizations. Make sure that each code is accompanied by a brief explanation. The whole\n",
        "process should be supported with verbose textual descriptions of your procedures and findings."
      ],
      "metadata": {
        "id": "D8Gkhb3DOdkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 6. Initial model training\n",
        "Use machine learning models to accomplish your chosen task (i.e., classification or regression)\n",
        "for the dataset. In this section of the notebook, please take note of the following:\n",
        "\n",
        "* The project should train and evaluate <u>at least 3 different kinds</u> of machine learning\n",
        "models. The models <u>should</u> not be multiple variations of the same model, e.g., three\n",
        "neural network models with different number of neurons.\n",
        "\n",
        "* Each model should be appropriate in accomplishing the chosen task for the dataset.\n",
        "There should be a clear and correct justification on the use of each machine learning\n",
        "model.\n",
        "\n",
        "* Make sure that the values of the hyperparameters of each model are mentioned. At the\n",
        "minimum, the optimizer, the learning rate, and the learning rate schedule should be\n",
        "discussed per model.\n",
        "\n",
        "* The report should show that the models are not overfitting nor underfitting."
      ],
      "metadata": {
        "id": "aUZxlf3SOdnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 7. Error analysis\n",
        "Perform error analysis on the output of all models used in the project. In this section of the\n",
        "notebook, you should:\n",
        "* Report and properly interpret the initial performance of all models using appropriate\n",
        "evaluation metrics.\n",
        "* Identify difficult classes and/or instances. For classification tasks, these are classes\n",
        "and/or instances that are difficult to classify. Hint: You may use confusion matrix for\n",
        "this. For regression tasks, these are instances that produces high error."
      ],
      "metadata": {
        "id": "84yx3XccOdpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 8. Improving model performance\n",
        "* Perform grid search or random search to tune the hyperparameters of each model. You should\n",
        "also tune each model to reduce the error in difficult classes and/or instances. In this section of\n",
        "the notebook, please take note of the following:\n",
        "* Make sure to elaborately explain the method of hyperparameter tuning.\n",
        "* Explicitly mention the different hyperparameters and their range of values. Show the\n",
        "corresponding performance of each configuration.\n",
        "* Report the performance of all models using appropriate evaluation metrics and\n",
        "visualizations.\n",
        "* Properly interpret the result based on relevant evaluation metrics.\n"
      ],
      "metadata": {
        "id": "Xkiecd3VOdry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 9. Model performance summary\n",
        "Present a summary of all model configurations. In this section of the notebook, do the\n",
        "following:\n",
        "* Discuss each algorithm and the best set of values for its hyperparameters. Identify the\n",
        "best model configuration and discuss its advantage over other configurations.\n",
        "* Discuss how tuning each model helped in reducing its error in difficult classes and/or\n",
        "instances."
      ],
      "metadata": {
        "id": "Q0kPq8bUPXDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 10. Insights and conclusions\n",
        "Clearly state your insights and conclusions from training a model on the data. Why did some\n",
        "models produce better results? Summarize your conclusions to explain the performance of the\n",
        "models. Discuss recommendations to improve the performance of the model."
      ],
      "metadata": {
        "id": "nbBKgYUHPXGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 11. References\n",
        "Cite relevant references that you used in your project. All references must be cited, including:\n",
        "* Scholarly Articles – Cite in APA format and put a description of how you used it for your\n",
        "work.\n",
        "* Online references, blogs, articles that helped you come up with your project – Put the\n",
        "website, blog, or article title, link, and how you incorporated it into your work.\n",
        "* Artificial Intelligence (AI) Tools – Put the model used (e.g., ChatGPT, Gemini), the complete\n",
        "transcript of your conversations with the model (including your prompts and its\n",
        "responses), and a description of how you used it for your work.\n",
        "\n",
        "*(Psst. Use [Zotero](https://www.zotero.org/))*"
      ],
      "metadata": {
        "id": "m72BLI-fPXIi"
      }
    }
  ]
}